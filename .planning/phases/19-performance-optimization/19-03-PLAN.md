# Plan: 19-03 Context Token Optimization & Metrics Dashboard

## Objective

Reduce context/token usage through smart truncation and lazy loading, then create a metrics dashboard for visibility into performance gains.

## Execution Context

**Phase:** 19 - performance-optimization
**Plan:** 3 of 3
**Depends on:** 19-02 complete

**Key files:**
- `lib/context/context-predictor.js` - Prediction logic
- `lib/memory/global-memory.js` - Pattern storage
- `lib/profile/profile-manager.js` - Developer profile

## Context

### Current State (after 19-02)
- Performance metrics tracking in place
- File I/O optimized with caching
- Keyword lookups now O(1)
- Relationship graph persisted

### Performance Bottlenecks Addressed
1. **Context overload** - All predictions returned, no truncation
2. **Pattern bloat** - All patterns loaded, not just high-confidence
3. **Profile size** - Full profile loaded every time
4. **No visibility** - Metrics collected but not displayed

### Target Outcomes
- Top-N predictions only (configurable, default 5)
- Lazy load patterns (top 20 high-confidence first)
- Compressed profile export for context
- Performance dashboard in /gywd:context command

## Tasks

<task id="1" title="Implement prediction result truncation">
**Action:** Limit prediction results to top N with configurable threshold

**Implementation:**
Modify `lib/context/context-predictor.js`:
```javascript
class ContextPredictor {
  constructor(options = {}) {
    // ... existing
    this.maxPredictions = options.maxPredictions || 5;
    this.minConfidence = options.minConfidence || 0.3;
  }

  predictForTask(taskDescription, options = {}) {
    const limit = options.limit || this.maxPredictions;
    const minConf = options.minConfidence || this.minConfidence;

    const allPredictions = this._computePredictions(taskDescription);

    // Filter and truncate
    const filtered = allPredictions
      .filter(p => p.confidence >= minConf)
      .sort((a, b) => b.confidence - a.confidence)
      .slice(0, limit);

    // Track truncation for metrics
    tracker.trackPrediction({
      total: allPredictions.length,
      returned: filtered.length,
      truncated: allPredictions.length - filtered.length
    });

    return filtered;
  }

  // For cases where user wants all
  predictForTaskFull(taskDescription) {
    return this._computePredictions(taskDescription);
  }
}
```

**Files:**
- Modify: `lib/context/context-predictor.js`

**Verification:**
- [ ] Default returns max 5 predictions
- [ ] Low confidence predictions filtered
- [ ] Full predictions available via separate method
- [ ] Truncation tracked in metrics
</task>

<task id="2" title="Implement lazy pattern loading">
**Action:** Load only top 20 high-confidence patterns initially, lazy load rest

**Implementation:**
Modify `lib/memory/global-memory.js`:
```javascript
class GlobalMemory {
  constructor() {
    // ... existing
    this.lazyLoadThreshold = 20;
    this.minPatternConfidence = 0.7;
    this._fullPatternsLoaded = false;
  }

  load() {
    // Load only top patterns initially
    this._loadTopPatterns();
  }

  _loadTopPatterns() {
    const allPatterns = this._readPatternsFile();
    this.patterns = allPatterns
      .filter(p => p.confidence >= this.minPatternConfidence)
      .sort((a, b) => b.confidence - a.confidence)
      .slice(0, this.lazyLoadThreshold);

    this._allPatternsCount = allPatterns.length;
  }

  _loadFullPatterns() {
    if (this._fullPatternsLoaded) return;

    this.patterns = this._readPatternsFile();
    this._fullPatternsLoaded = true;
    tracker.trackPatternLoad('full', this.patterns.length);
  }

  getPattern(type, context) {
    // Try top patterns first
    const found = this.patterns.find(p => p.type === type && this._matchContext(p, context));
    if (found) return found;

    // Lazy load full if not found
    if (!this._fullPatternsLoaded) {
      this._loadFullPatterns();
      return this.patterns.find(p => p.type === type && this._matchContext(p, context));
    }

    return null;
  }

  getPatternStats() {
    return {
      loaded: this.patterns.length,
      total: this._allPatternsCount,
      lazyLoaded: this._fullPatternsLoaded
    };
  }
}
```

**Files:**
- Modify: `lib/memory/global-memory.js`

**Verification:**
- [ ] Initial load only gets top 20 patterns
- [ ] Full load triggered when pattern not found
- [ ] Memory reduction on startup
- [ ] Stats show loaded vs total
</task>

<task id="3" title="Create compressed profile export">
**Action:** Add profile summary for context-constrained scenarios

**Implementation:**
Add to `lib/profile/profile-manager.js`:
```javascript
class ProfileManager {
  // ... existing

  getCompactProfile() {
    // Return only essential profile data for context
    const profile = this.getProfile();
    return {
      id: profile.id,
      name: profile.name,
      topExpertise: profile.expertise
        .sort((a, b) => b.confidence - a.confidence)
        .slice(0, 5)
        .map(e => e.area),
      topPreferences: Object.entries(profile.preferences)
        .filter(([_, v]) => v.confidence > 0.8)
        .slice(0, 10)
        .reduce((acc, [k, v]) => ({ ...acc, [k]: v.value }), {}),
      recentPatterns: profile.patterns
        .slice(-5)
        .map(p => p.type)
    };
  }

  getProfileSize() {
    const full = JSON.stringify(this.getProfile()).length;
    const compact = JSON.stringify(this.getCompactProfile()).length;
    return {
      full,
      compact,
      reduction: Math.round((1 - compact / full) * 100)
    };
  }
}
```

**Files:**
- Modify: `lib/profile/profile-manager.js`

**Verification:**
- [ ] Compact profile < 1KB typical
- [ ] 70%+ size reduction from full profile
- [ ] Essential information preserved
- [ ] Size stats available
</task>

<task id="4" title="Create performance metrics dashboard">
**Action:** Add metrics display to /gywd:context command output

**Implementation:**
Create `lib/metrics/dashboard.js`:
```javascript
class MetricsDashboard {
  constructor(tracker) {
    this.tracker = tracker;
  }

  render() {
    const m = this.tracker.getReport();

    return `
## Performance Metrics

### Cache Performance
| Cache | Size | Hit Rate | Avg Hit Time |
|-------|------|----------|--------------|
| File Content | ${m.cache.fileContent.size} | ${this._pct(m.cache.fileContent.hitRate)} | ${m.cache.fileContent.avgHitTimeMs}ms |
| Metadata | ${m.cache.metadata.size} | ${this._pct(m.cache.metadata.hitRate)} | ${m.cache.metadata.avgHitTimeMs}ms |
| Predictions | ${m.cache.predictions.size} | ${this._pct(m.cache.predictions.hitRate)} | ${m.cache.predictions.avgHitTimeMs}ms |

### File I/O
| Metric | Count | Bytes |
|--------|-------|-------|
| Reads | ${m.fileIO.reads} | ${this._bytes(m.fileIO.readBytes)} |
| Writes | ${m.fileIO.writes} | ${this._bytes(m.fileIO.writeBytes)} |
| Scans | ${m.fileIO.scans} | - |

### Memory Optimization
| Metric | Value |
|--------|-------|
| Patterns (loaded/total) | ${m.memory.patternsLoaded}/${m.memory.patternsTotal} |
| Profile size reduction | ${m.memory.profileReduction}% |
| Batched writes | ${m.memory.batchedWrites} |
| Prediction truncations | ${m.memory.predictionTruncations} |

### Commands
| Metric | Value |
|--------|-------|
| Cached commands | ${m.commands.cached} |
| Command cache hit rate | ${this._pct(m.commands.hitRate)} |
| Session uptime | ${this._duration(m.sessionUptime)} |
`;
  }

  _pct(rate) {
    return `${Math.round(rate * 100)}%`;
  }

  _bytes(n) {
    if (n < 1024) return `${n}B`;
    if (n < 1024 * 1024) return `${(n / 1024).toFixed(1)}KB`;
    return `${(n / (1024 * 1024)).toFixed(1)}MB`;
  }

  _duration(ms) {
    const s = Math.floor(ms / 1000);
    const m = Math.floor(s / 60);
    return m > 0 ? `${m}m ${s % 60}s` : `${s}s`;
  }
}

module.exports = { MetricsDashboard };
```

**Files:**
- Create: `lib/metrics/dashboard.js`
- Modify: `lib/metrics/index.js` to export

**Verification:**
- [ ] Dashboard renders markdown table
- [ ] All metrics displayed
- [ ] Human-readable formatting
</task>

<task id="5" title="Integrate dashboard into context command">
**Action:** Add --perf flag to show metrics in /gywd:context

**Implementation:**
Update `commands/gywd/context.md`:
```markdown
## Options

- `--perf` - Show performance metrics dashboard
- `--compact` - Use compact profile export

## Behavior

If `--perf` flag provided:
1. Load performance tracker
2. Render metrics dashboard
3. Append to context output

If `--compact` flag provided:
1. Use getCompactProfile() instead of full profile
2. Use truncated predictions (top 5)
```

**Files:**
- Modify: `commands/gywd/context.md`
- Create: `lib/context/context-exporter.js` (if needed)

**Verification:**
- [ ] /gywd:context --perf shows metrics
- [ ] /gywd:context --compact reduces output size
- [ ] Default behavior unchanged
</task>

<task id="6" title="Add optimization tests and documentation">
**Action:** Create tests and update docs for new optimizations

**Implementation:**
Create tests in `tests/performance/`:
```javascript
describe('Token Optimization', () => {
  describe('Prediction Truncation', () => {
    test('default returns max 5 predictions', () => {
      const results = predictor.predictForTask('complex task');
      expect(results.length).toBeLessThanOrEqual(5);
    });

    test('respects custom limit', () => {
      const results = predictor.predictForTask('task', { limit: 3 });
      expect(results.length).toBeLessThanOrEqual(3);
    });
  });

  describe('Lazy Pattern Loading', () => {
    test('initial load has max 20 patterns', () => {
      memory.load();
      expect(memory.patterns.length).toBeLessThanOrEqual(20);
    });
  });

  describe('Compact Profile', () => {
    test('compact is < 30% of full size', () => {
      const sizes = profileManager.getProfileSize();
      expect(sizes.reduction).toBeGreaterThan(70);
    });
  });
});
```

Update `docs/PERFORMANCE.md`:
```markdown
# Performance Optimization

## Configuration

```javascript
// Prediction limits
predictor.maxPredictions = 5;    // Default
predictor.minConfidence = 0.3;   // Default

// Pattern loading
memory.lazyLoadThreshold = 20;   // Default
memory.minPatternConfidence = 0.7; // Default
```

## Metrics Dashboard

Use `/gywd:context --perf` to view performance metrics.
```

**Files:**
- Create: `tests/performance/token-optimization.test.js`
- Create: `docs/PERFORMANCE.md`

**Verification:**
- [ ] All optimization tests pass
- [ ] Documentation complete
- [ ] Examples work correctly
</task>

## Verification

```bash
cd "C:\Users\Prithvi Putta\PMP-GYWD"

# Run all tests
npm test

# Check performance improvements
npm test -- tests/performance/

# Test context command
npm run gywd -- context --perf
npm run gywd -- context --compact
```

## Success Criteria

- [ ] Predictions truncated to top 5 by default
- [ ] Patterns lazy-loaded (top 20 first)
- [ ] Compact profile export available
- [ ] Metrics dashboard renders correctly
- [ ] /gywd:context --perf flag works
- [ ] /gywd:context --compact flag works
- [ ] All 557+ existing tests pass
- [ ] PERFORMANCE.md documentation created

## Confidence Summary

**Overall: 85%** (High)

| Task | Confidence | Notes |
|------|------------|-------|
| T1: Prediction truncation | 92% | Simple filtering logic |
| T2: Lazy pattern loading | 80% | Lazy load trigger logic |
| T3: Compact profile | 90% | Well-defined reduction |
| T4: Metrics dashboard | 88% | Markdown rendering |
| T5: Command integration | 78% | Skill/command coordination |
| T6: Tests and docs | 90% | Standard patterns |

**Factors affecting confidence:**
- Command integration depends on skill execution model
- Lazy loading trigger conditions need validation
- Dashboard formatting for various terminal widths

## Output

After execution, provide:
1. Token/context reduction metrics
2. Dashboard output sample
3. Before/after profile sizes
4. Test results summary
5. Link to PERFORMANCE.md

## Checkpoint

<checkpoint type="human-verify" after="task-4">
Before integrating into context command, verify:
- Dashboard renders correctly in terminal
- Metrics are accurate and meaningful
- No information overload in output
</checkpoint>
